{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a90499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T02:55:51.159510Z",
     "iopub.status.busy": "2025-04-22T02:55:51.159177Z",
     "iopub.status.idle": "2025-04-22T02:55:55.804449Z",
     "shell.execute_reply": "2025-04-22T02:55:55.803324Z"
    },
    "papermill": {
     "duration": 4.651222,
     "end_time": "2025-04-22T02:55:55.806690",
     "exception": false,
     "start_time": "2025-04-22T02:55:51.155468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\r\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (19.0.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.1)\r\n"
     ]
    }
   ],
   "source": [
    "# Turn on Internet in Notebook Settings → Internet → On, then save.\n",
    "\n",
    "# Install only the extras we truly need:\n",
    "!pip install beautifulsoup4 joblib pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d8ef05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T02:55:55.812826Z",
     "iopub.status.busy": "2025-04-22T02:55:55.812485Z",
     "iopub.status.idle": "2025-04-22T02:55:58.026155Z",
     "shell.execute_reply": "2025-04-22T02:55:58.025137Z"
    },
    "papermill": {
     "duration": 2.218488,
     "end_time": "2025-04-22T02:55:58.027733",
     "exception": false,
     "start_time": "2025-04-22T02:55:55.809245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Only need stopwords and punkt for our preprocessing\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4087b40b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T02:55:58.033599Z",
     "iopub.status.busy": "2025-04-22T02:55:58.032845Z",
     "iopub.status.idle": "2025-04-22T02:56:01.820153Z",
     "shell.execute_reply": "2025-04-22T02:56:01.819234Z"
    },
    "papermill": {
     "duration": 3.791634,
     "end_time": "2025-04-22T02:56:01.821650",
     "exception": false,
     "start_time": "2025-04-22T02:55:58.030016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (84438, 2)\n",
      "label\n",
      "1    43827\n",
      "0    40611\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[zzzzteana] RE: Alexander Martin A posted: Tas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[zzzzteana] Moscow bomber Man Threatens Explos...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[IRR] Klez: The Virus That Won't Die Klez: The...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; making a pizza a deep-pie; I just had to jum...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  label\n",
       "0                                                         0\n",
       "1  [zzzzteana] RE: Alexander Martin A posted: Tas...      0\n",
       "2  [zzzzteana] Moscow bomber Man Threatens Explos...      0\n",
       "3  [IRR] Klez: The Virus That Won't Die Klez: The...      0\n",
       "4  > making a pizza a deep-pie; I just had to jum...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Adjust to match your dataset slug; Kaggle mounts under /kaggle/input/\n",
    "df = pd.read_parquet('/kaggle/input/phish-ai-dataset/dataset.parquet')\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df['label'].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa6851f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T02:56:01.828090Z",
     "iopub.status.busy": "2025-04-22T02:56:01.827408Z",
     "iopub.status.idle": "2025-04-22T02:57:00.969407Z",
     "shell.execute_reply": "2025-04-22T02:57:00.968486Z"
    },
    "papermill": {
     "duration": 59.148945,
     "end_time": "2025-04-22T02:57:00.973110",
     "exception": false,
     "start_time": "2025-04-22T02:56:01.824165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      8122\n",
      "           1       0.99      0.99      0.99      8766\n",
      "\n",
      "    accuracy                           0.99     16888\n",
      "   macro avg       0.99      0.99      0.99     16888\n",
      "weighted avg       0.99      0.99      0.99     16888\n",
      "\n",
      "ROC‑AUC: 0.9991908980113502\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['body'], df['label'],\n",
    "    test_size=0.2,\n",
    "    stratify=df['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Vectorizer & classifier\n",
    "vect = TfidfVectorizer(\n",
    "    max_features=50000,\n",
    "    ngram_range=(1,2),\n",
    "    stop_words='english'\n",
    ")\n",
    "clf = LogisticRegression(max_iter=300, C=4)\n",
    "\n",
    "# Fit\n",
    "Xtr = vect.fit_transform(X_train)\n",
    "clf.fit(Xtr, y_train)\n",
    "\n",
    "# Evaluate\n",
    "Xte = vect.transform(X_test)\n",
    "preds = clf.predict(Xte)\n",
    "probs = clf.predict_proba(Xte)[:,1]\n",
    "\n",
    "print(classification_report(y_test, preds))\n",
    "print(\"ROC‑AUC:\", roc_auc_score(y_test, probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48bd1216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T02:57:00.979563Z",
     "iopub.status.busy": "2025-04-22T02:57:00.979175Z",
     "iopub.status.idle": "2025-04-22T03:03:09.635038Z",
     "shell.execute_reply": "2025-04-22T03:03:09.633938Z"
    },
    "papermill": {
     "duration": 368.664378,
     "end_time": "2025-04-22T03:03:09.640052",
     "exception": false,
     "start_time": "2025-04-22T02:57:00.975674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best params: {'vect__ngram_range': (1, 2), 'vect__max_features': 20000, 'clf__C': 10.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer(stop_words=\"english\")),\n",
    "    (\"clf\",  LogisticRegression(solver=\"liblinear\", max_iter=500)),\n",
    "])\n",
    "param_dist = {\n",
    "    \"vect__max_features\": [20000, 50000],\n",
    "    \"vect__ngram_range\": [(1,1), (1,2)],\n",
    "    \"clf__C\": np.logspace(-1, 1, 5),\n",
    "}\n",
    "search = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=6,\n",
    "    cv=3,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=2,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best params:\", search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18803726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T03:03:09.649261Z",
     "iopub.status.busy": "2025-04-22T03:03:09.648902Z",
     "iopub.status.idle": "2025-04-22T03:03:22.736213Z",
     "shell.execute_reply": "2025-04-22T03:03:22.735085Z"
    },
    "papermill": {
     "duration": 13.093697,
     "end_time": "2025-04-22T03:03:22.737703",
     "exception": false,
     "start_time": "2025-04-22T03:03:09.644006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the vectorizer & classifier\n",
    "joblib.dump(vect, 'vect.joblib')\n",
    "joblib.dump(clf,  'clf.joblib')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7215469,
     "sourceId": 11507771,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 458.926722,
   "end_time": "2025-04-22T03:03:25.461975",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-22T02:55:46.535253",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
